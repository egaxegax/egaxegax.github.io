<!--2025-02-27 13:47:39-->
<div class="yb">
  <div class="rss smaller1 habr"><img src="https://habrastorage.org/getpro/habr/upload_files/189/dad/3f1/189dad3f178191578e99f4ea12087a6e.jpg" /><p>Текущие большие языковые модели (LLM) являются авторегрессивными, то есть генерируют текст слева направо, по одному токену за раз. Этот процесс по своей природе последовательный — новый токен не может быть сгенерирован, пока не сформирован весь предшествующий... <br><a class="light" href="https://habr.com/ru/news/886432/?utm_source=habrahabr&utm_medium=rss&utm_campaign=886432">Вышел Mercury Coder: первая модель на принципиально новой архитектуре dLLM, в 10 раз быстрее LLM</a></div>
</div>
