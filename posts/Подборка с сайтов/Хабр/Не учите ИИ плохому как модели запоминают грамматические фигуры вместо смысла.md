<!--2025-12-02 14:36:46-->
<div class="yb">
  <div class="rss mw_f scroll habr"><img src="https://habrastorage.org/getpro/habr/upload_files/e65/39f/191/e6539f1918f888ae2a2ff4ba92091a3f.png" /><p>Крупные языковые модели (LLM), подобные тем, что&nbsp;лежат в&nbsp;основе ChatGPT, порой ставят&nbsp;<strong>структуру предложения выше его смысла</strong>. Иными словами, они отвечают не&nbsp;на&nbsp;то,&nbsp;<em>что</em>&nbsp;вы спросили, а&nbsp;на&nbsp;то,&nbsp;<em>как</em>&nbsp;это грамматически оформлено.</p><p>Чтобы проверить гипотезу, исследователи задавал... <p class="titl"><a href="https://habr.com/ru/companies/bothub/news/972526/?utm_source=habrahabr&utm_medium=rss&utm_campaign=972526">Не учите ИИ плохому: как модели запоминают грамматические фигуры вместо смысла</a></p></div>
</div>
